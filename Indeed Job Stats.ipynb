{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Program to analyze and find salary of a job profile</center>\n",
    "### <center>by Sushant Deshpande</center>\n",
    "\n",
    "I wrote this program so that it can scrape and analyze several jobs listed on Indeed.com or Indeed.ca in this case since I am in Canada and find the average salary of jobs. In addition to this, it also tells us which city in Canada has the maximum number of jobs and maximum salary. I have plotted all this using bar graph to make it visually easy to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's start by asking the user which job title he wants search for. First, we create a variable called <b> *job_title_1*</b> and store the user input in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Job Title: Data Scientist\n"
     ]
    }
   ],
   "source": [
    "job_title_1 = input(\"Enter the Job Title: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's import the required libries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import time\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way Indeed works is it takes the given user input, converts it to lower case and replaces the spaces with +. So we need to do the same.\n",
    "\n",
    "Let's convert the job title to lower case using <b>.lower()</b> method.\n",
    "\n",
    "Then, let's replace the spaces with + using <b>.repalce()</b> method.\n",
    "\n",
    "And then let's see how the output looks, <b>job_title_3</b> in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data+scientist'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title_2 = job_title_1.lower() # convert to lower case\n",
    "job_title_3 = job_title_2.replace(' ', '+') # replace space with +\n",
    "job_title_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, since we are searching for <b>Data Scientist</b> the output looks good, <b>*data+scientist*</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write the code that can scrape Indeed.ca with our <b>*job_title_3*</b>\n",
    "\n",
    "Here we insert job_title_3 into our url using concatenate feature in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.indeed.ca/jobs?q='+job_title_3+'&l=canada'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the url that we just parsed, just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.ca/jobs?q=data+scientist&l=canada'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the the url, let's write a function that will parse the url, extract the data and store it in a dataframe.\n",
    "\n",
    "In order to get a proper data set, we need to parse more than one page. So let's write the code to parse first 10 pages and store them in the same dataframe using <b>pd.concat</b> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science / Machine Vision Intern</td>\n",
       "      <td>None</td>\n",
       "      <td>Relay Medical Corp.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>autoTRADER.ca</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Integrity Data Scientist</td>\n",
       "      <td>Calgary, AB</td>\n",
       "      <td>TC Energy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Wrangler</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>John Deere</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Quebec City, QC</td>\n",
       "      <td>Targeted Talent</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title         Location              Company  \\\n",
       "0  Data Science / Machine Vision Intern             None  Relay Medical Corp.   \n",
       "1                        Data Scientist             None        autoTRADER.ca   \n",
       "2              Integrity Data Scientist      Calgary, AB            TC Energy   \n",
       "3                         Data Wrangler          Ontario           John Deere   \n",
       "4                        Data Scientist  Quebec City, QC      Targeted Talent   \n",
       "\n",
       "  Salary  \n",
       "0   None  \n",
       "1   None  \n",
       "2   None  \n",
       "3   None  \n",
       "4   None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse(url):\n",
    "    time.sleep(5)\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\"])\n",
    "    for each in soup.find_all(class_= \"result\" ):\n",
    "        time.sleep(5)\n",
    "        try: \n",
    "            title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "        except:\n",
    "            title = 'None'\n",
    "        try:\n",
    "            location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "        except:\n",
    "            location = 'None'\n",
    "        try: \n",
    "            company = each.find(class_='company').text.replace('\\n', '')\n",
    "        except:\n",
    "            company = 'None'\n",
    "        try:\n",
    "            salary = each.find('span', {'class':'no-wrap'}).text.replace('\\n', '')\n",
    "        except:\n",
    "            salary = 'None'\n",
    "        #synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "        df = df.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary}, ignore_index=True)\n",
    "    return df\n",
    "df1 = parse(url)\n",
    "url_1 = url + \"&start=20\"\n",
    "time.sleep(5)\n",
    "url_2 = url + \"&start=40\"\n",
    "time.sleep(5)\n",
    "url_3 = url + \"&start=60\"\n",
    "time.sleep(5)\n",
    "url_4 = url + \"&start=80\"\n",
    "time.sleep(5)\n",
    "url_5 = url + \"&start=100\"\n",
    "time.sleep(5)\n",
    "url_6 = url + \"&start=120\"\n",
    "time.sleep(5)\n",
    "url_7 = url + \"&start=140\"\n",
    "time.sleep(5)\n",
    "url_8 = url + \"&start=160\"\n",
    "time.sleep(5)\n",
    "url_9 = url + \"&start=180\"\n",
    "time.sleep(5)\n",
    "url_10 = url + \"&start=200\"\n",
    "\n",
    "df2 = parse(url_1)\n",
    "df3 = parse(url_2)\n",
    "df4 = parse(url_3)\n",
    "df5 = parse(url_4)\n",
    "df6 = parse(url_5)\n",
    "df7 = parse(url_6)\n",
    "df8 = parse(url_7)\n",
    "df9 = parse(url_8)\n",
    "df10 = parse(url_9)\n",
    "df11 = parse(url_10)\n",
    "\n",
    "data1 = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11], axis=0, ignore_index=True)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the dataset, we can see that it has a lot of stuff that we don't need like \\n, $ etc. So let's clean up the data.\n",
    "\n",
    "When we check the data type of data1, we can see that <b>Salary</b> is stored as an object. In addition to that, Salary is defined as per year, per month, per week and per hour. In order for our analysis to work, we need to have salary displayed as per year and the column salary itself should be either <b>*float*</b> or <b>*int*</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title       object\n",
       "Location    object\n",
       "Company     object\n",
       "Salary      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.dtypes # here, salary is an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sal_year_temp = data1[data1['Salary'].str.contains(' a year')].reset_index(drop=True)\n",
    "data_sal_year_1a = data_sal_year_temp.replace(' a year', '', regex=True) # replace 'a year'\n",
    "data_sal_year_1 = data_sal_year_1a.replace('\\n', '', regex=True) # replace \\n\n",
    "data_sal_year_2 = data_sal_year_1.replace('[\\$,)]', '', regex=True) # replace $\n",
    "data_sal_year_3a = data_sal_year_2['Salary'].str.split('-', expand=True)\n",
    "data_sal_year_3a.iloc[:, :] = data_sal_year_3a.iloc[:, :].astype('float')\n",
    "data_sal_year_3b = data_sal_year_3a.sum(axis=1).astype('float')\n",
    "data_sal_year_3c = (data_sal_year_3b/2)\n",
    "data_sal_year_3 = data_sal_year_3c.astype('int')\n",
    "data_sal_year_5 = pd.concat([data_sal_year_2, data_sal_year_3], axis=1, sort=True)\n",
    "data_sal_year_6 = data_sal_year_5.drop(['Salary'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segment takes the salary per month and converts it to per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sal_month_temp = data1[data1['Salary'].str.contains(' a month')].reset_index(drop=True)\n",
    "data_sal_month_1a = data_sal_month_temp.replace(' a month', '', regex=True)\n",
    "data_sal_month_1 = data_sal_month_1a.replace('\\n', '', regex=True)\n",
    "data_sal_month_2 = data_sal_month_1.replace('[\\$,)]', '', regex=True)\n",
    "data_sal_month_3a = data_sal_month_2['Salary'].str.split('-', expand=True)\n",
    "data_sal_month_3a.iloc[:, :] = data_sal_month_3a.iloc[:, :].astype('float')\n",
    "data_sal_month_3b = data_sal_month_3a.sum(axis=1).astype('float')\n",
    "data_sal_month_3c = (data_sal_month_3b/2) * 12\n",
    "data_sal_month_3 = data_sal_month_3c.astype('int')\n",
    "data_sal_month_5 = pd.concat([data_sal_month_2, data_sal_month_3], axis=1, sort=True)\n",
    "data_sal_month_6 = data_sal_month_5.drop(['Salary'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segment takes the salary per week and converts it to per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sal_week_temp = data1[data1['Salary'].str.contains(' a week')].reset_index(drop=True)\n",
    "data_sal_week_1a = data_sal_week_temp.replace(' a week', '', regex=True)\n",
    "data_sal_week_1 = data_sal_week_1a.replace('\\n', '', regex=True)\n",
    "data_sal_week_2 = data_sal_week_1.replace('[\\$,)]', '', regex=True)\n",
    "data_sal_week_3a = data_sal_week_2['Salary'].str.split('-', expand=True)\n",
    "data_sal_week_3a.iloc[:, :] = data_sal_week_3a.iloc[:, :].astype('float')\n",
    "data_sal_week_3b = data_sal_week_3a.sum(axis=1).astype('float')\n",
    "data_sal_week_3c = (data_sal_week_3b/2) * 52\n",
    "data_sal_week_3 = data_sal_week_3c.astype('int')\n",
    "data_sal_week_5 = pd.concat([data_sal_week_2, data_sal_week_3], axis=1, sort=True)\n",
    "data_sal_week_6 = data_sal_week_5.drop(['Salary'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segment takes the salary per hour and converts it to per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sal_hour_temp = data1[data1['Salary'].str.contains(' an hour')].reset_index(drop=True)\n",
    "data_sal_hour_1a = data_sal_hour_temp.replace(' an hour', '', regex=True)\n",
    "data_sal_hour_1 = data_sal_hour_1a.replace('\\n', '', regex=True)\n",
    "data_sal_hour_2 = data_sal_hour_1.replace('[\\$,)]', '', regex=True)\n",
    "data_sal_hour_3a = data_sal_hour_2['Salary'].str.split('-', expand=True)\n",
    "data_sal_hour_3a.iloc[:, :] = data_sal_hour_3a.iloc[:, :].astype('float')\n",
    "data_sal_hour_3b = data_sal_hour_3a.sum(axis=1).astype('float')\n",
    "data_sal_hour_3c = (data_sal_hour_3b/2) * 40 * 52\n",
    "data_sal_hour_3 = data_sal_hour_3c.astype('int')\n",
    "data_sal_hour_5 = pd.concat([data_sal_hour_2, data_sal_hour_3], axis=1, sort=True)\n",
    "data_sal_hour_6 = data_sal_hour_5.drop(['Salary'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the rows that don't have any salary mentioned and save them in <b>data_sal_none_temp</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science / Machine Vision Intern</td>\n",
       "      <td>None</td>\n",
       "      <td>Relay Medical Corp.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>autoTRADER.ca</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Integrity Data Scientist</td>\n",
       "      <td>Calgary, AB</td>\n",
       "      <td>TC Energy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Wrangler</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>John Deere</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Quebec City, QC</td>\n",
       "      <td>Targeted Talent</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title         Location              Company  \\\n",
       "0  Data Science / Machine Vision Intern             None  Relay Medical Corp.   \n",
       "1                        Data Scientist             None        autoTRADER.ca   \n",
       "2              Integrity Data Scientist      Calgary, AB            TC Energy   \n",
       "3                         Data Wrangler          Ontario           John Deere   \n",
       "4                        Data Scientist  Quebec City, QC      Targeted Talent   \n",
       "\n",
       "  Salary  \n",
       "0   None  \n",
       "1   None  \n",
       "2   None  \n",
       "3   None  \n",
       "4   None  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sal_none_temp = data1[data1['Salary'].str.contains('None')].reset_index(drop=True)\n",
    "data_sal_none_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's bring together our newly formed dataset and save it as <b>data_sal_all</b> and rename the table header as <b>Title</b>, <b>Location</b>, <b>Company</b> and <b>Salary</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analytics Client Lead and Development</td>\n",
       "      <td>Toronto ON</td>\n",
       "      <td>Advanced Analytics and Research Lab (AAARL</td>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Senior Business Data Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>WeyMedia Inc.</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Bus Priority Programs</td>\n",
       "      <td>Metro Vancouver Regional District BC</td>\n",
       "      <td>TransLink</td>\n",
       "      <td>34282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>Vancouver BC</td>\n",
       "      <td>ProCogia</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>None</td>\n",
       "      <td>ProCogia</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title  \\\n",
       "0    Analytics Client Lead and Development   \n",
       "15            Senior Business Data Analyst   \n",
       "4   Data Scientist - Bus Priority Programs   \n",
       "3                  Data Science Consultant   \n",
       "18                 Data Science Consultant   \n",
       "\n",
       "                                Location  \\\n",
       "0                             Toronto ON   \n",
       "15                                  None   \n",
       "4   Metro Vancouver Regional District BC   \n",
       "3                           Vancouver BC   \n",
       "18                                  None   \n",
       "\n",
       "                                       Company  Salary  \n",
       "0   Advanced Analytics and Research Lab (AAARL   21000  \n",
       "15                               WeyMedia Inc.   30000  \n",
       "4                                    TransLink   34282  \n",
       "3                                     ProCogia   35000  \n",
       "18                                    ProCogia   35000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sal_all = pd.concat([data_sal_year_6, data_sal_month_6, data_sal_week_6, data_sal_hour_6], axis=0, sort=True)\n",
    "data_sal_all.columns = ['Title', 'Location', 'Company', 'Salary']\n",
    "data_sal_all.sort_values(by='Salary',ascending=True, inplace=True)\n",
    "data_sal_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's join the two data sets, <b>data_sal_all</b> and <b>data_sal_none_temp</b> and save them in <b>data_sal_all_1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advanced Analytics and Research Lab (AAARL</td>\n",
       "      <td>Toronto ON</td>\n",
       "      <td>21000</td>\n",
       "      <td>Analytics Client Lead and Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WeyMedia Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>30000</td>\n",
       "      <td>Senior Business Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TransLink</td>\n",
       "      <td>Metro Vancouver Regional District BC</td>\n",
       "      <td>34282</td>\n",
       "      <td>Data Scientist - Bus Priority Programs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ProCogia</td>\n",
       "      <td>Vancouver BC</td>\n",
       "      <td>35000</td>\n",
       "      <td>Data Science Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ProCogia</td>\n",
       "      <td>None</td>\n",
       "      <td>35000</td>\n",
       "      <td>Data Science Consultant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Company  \\\n",
       "0   Advanced Analytics and Research Lab (AAARL   \n",
       "15                               WeyMedia Inc.   \n",
       "4                                    TransLink   \n",
       "3                                     ProCogia   \n",
       "18                                    ProCogia   \n",
       "\n",
       "                                Location Salary  \\\n",
       "0                             Toronto ON  21000   \n",
       "15                                  None  30000   \n",
       "4   Metro Vancouver Regional District BC  34282   \n",
       "3                           Vancouver BC  35000   \n",
       "18                                  None  35000   \n",
       "\n",
       "                                     Title  \n",
       "0    Analytics Client Lead and Development  \n",
       "15            Senior Business Data Analyst  \n",
       "4   Data Scientist - Bus Priority Programs  \n",
       "3                  Data Science Consultant  \n",
       "18                 Data Science Consultant  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sal_all_1 = pd.concat([data_sal_all, data_sal_none_temp], axis=0, sort=True)\n",
    "data_sal_all_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the shape of <b>data_sal_all_1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sal_all_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of <b>data_sal_all_1</b> is <b>(283, 5)</b> which is same as the shape of <b>data1</b>.\n",
    "This proves that we successfully managed to merge the 2 datasets without missing any row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's replace <b>'None'</b> values with <b>np.nan</b> and change the data type of <b>Salary</b> to *float*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       21000.0\n",
       "15      30000.0\n",
       "4       34282.0\n",
       "3       35000.0\n",
       "18      35000.0\n",
       "0       46800.0\n",
       "1       47840.0\n",
       "1       53900.0\n",
       "7       70000.0\n",
       "17      85000.0\n",
       "9       88452.0\n",
       "5       90000.0\n",
       "11      90000.0\n",
       "12      90000.0\n",
       "13      90000.0\n",
       "0       92629.0\n",
       "16     100000.0\n",
       "6      100000.0\n",
       "2      100000.0\n",
       "14     100000.0\n",
       "8      105705.0\n",
       "10     112737.0\n",
       "0           NaN\n",
       "1           NaN\n",
       "2           NaN\n",
       "3           NaN\n",
       "4           NaN\n",
       "5           NaN\n",
       "6           NaN\n",
       "7           NaN\n",
       "         ...   \n",
       "115         NaN\n",
       "116         NaN\n",
       "117         NaN\n",
       "118         NaN\n",
       "119         NaN\n",
       "120         NaN\n",
       "121         NaN\n",
       "122         NaN\n",
       "123         NaN\n",
       "124         NaN\n",
       "125         NaN\n",
       "126         NaN\n",
       "127         NaN\n",
       "128         NaN\n",
       "129         NaN\n",
       "130         NaN\n",
       "131         NaN\n",
       "132         NaN\n",
       "133         NaN\n",
       "134         NaN\n",
       "135         NaN\n",
       "136         NaN\n",
       "137         NaN\n",
       "138         NaN\n",
       "139         NaN\n",
       "140         NaN\n",
       "141         NaN\n",
       "142         NaN\n",
       "143         NaN\n",
       "144         NaN\n",
       "Name: Salary, Length: 167, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5a = data_sal_all_1.replace('None',np.nan, regex=True)\n",
    "data5a['Salary'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find the mean of the the cell Sa;ary using the .mean() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73561.13636363637"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_1 = data5a['Salary'].mean()\n",
    "mean_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now replace the np.nan cells with the mean salary obtained in the previous step.\n",
    "\n",
    "Let's also change the datatype to *int*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data5b = data5a['Salary'].replace(np.nan, mean_1)\n",
    "data5ba = data5b.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's concact this salary to our previous dataframe <b>data_sal_all_1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Title</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Advanced Analytics and Research Lab (AAARL</td>\n",
       "      <td>Toronto ON</td>\n",
       "      <td>21000</td>\n",
       "      <td>Analytics Client Lead and Development</td>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>WeyMedia Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>30000</td>\n",
       "      <td>Senior Business Data Analyst</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>TransLink</td>\n",
       "      <td>Metro Vancouver Regional District BC</td>\n",
       "      <td>34282</td>\n",
       "      <td>Data Scientist - Bus Priority Programs</td>\n",
       "      <td>34282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ProCogia</td>\n",
       "      <td>Vancouver BC</td>\n",
       "      <td>35000</td>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>ProCogia</td>\n",
       "      <td>None</td>\n",
       "      <td>35000</td>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Nidish LLC</td>\n",
       "      <td>Remote</td>\n",
       "      <td>46800</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>46800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>CANN Forecast</td>\n",
       "      <td>Montréal QC</td>\n",
       "      <td>47840</td>\n",
       "      <td>CANN FORECAST | Machine Learning/Statistical A...</td>\n",
       "      <td>47840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>BC Pension Corporation</td>\n",
       "      <td>Victoria BC</td>\n",
       "      <td>53900</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>53900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>DocuPet</td>\n",
       "      <td>Calgary AB</td>\n",
       "      <td>70000</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>Oliver Solutions</td>\n",
       "      <td>Toronto ON</td>\n",
       "      <td>85000</td>\n",
       "      <td>Data Science and Analytics (DAS</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>Mastech InfoTrellis</td>\n",
       "      <td>Ottawa ON</td>\n",
       "      <td>88452</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>88452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>Fuze HR Solutions Inc</td>\n",
       "      <td>None</td>\n",
       "      <td>90000</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>Fuze HR Solutions Inc</td>\n",
       "      <td>None</td>\n",
       "      <td>90000</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>Fuze HR Solutions Inc</td>\n",
       "      <td>None</td>\n",
       "      <td>90000</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>Fuze HR Solutions Inc</td>\n",
       "      <td>None</td>\n",
       "      <td>90000</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>Innovation Credit Union</td>\n",
       "      <td>Canada</td>\n",
       "      <td>92629</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>92629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Staffinity Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>100000</td>\n",
       "      <td>Data Scientist/Machine Learning Engineer</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>Staffinity Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>100000</td>\n",
       "      <td>Data Scientist/Machine Learning Engineer</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>Staffinity Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>100000</td>\n",
       "      <td>Data Scientist/Machine Learning Engineer</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>Staffinity Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>100000</td>\n",
       "      <td>Data Scientist/Machine Learning Engineer</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>Canadian Security Intelligence Service</td>\n",
       "      <td>Ottawa ON</td>\n",
       "      <td>105705</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>105705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>Advanced Analytics and Research Lab</td>\n",
       "      <td>Toronto ON</td>\n",
       "      <td>112737</td>\n",
       "      <td>Advanced Analytics and Research Lab</td>\n",
       "      <td>112737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>Relay Medical Corp.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Science / Machine Vision Intern</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>autoTRADER.ca</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>TC Energy</td>\n",
       "      <td>Calgary, AB</td>\n",
       "      <td>None</td>\n",
       "      <td>Integrity Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>John Deere</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Wrangler</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>Targeted Talent</td>\n",
       "      <td>Quebec City, QC</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>Léger</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Business Intelligence and Analytics Developer</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>General Motors</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist - CCA Co-Op (Spring 2021)</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>115</td>\n",
       "      <td>BrainStation</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>None</td>\n",
       "      <td>Associate Educator, Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>116</td>\n",
       "      <td>Aviva</td>\n",
       "      <td>Markham, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Manager, Data Science Engineering</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>117</td>\n",
       "      <td>Hitachi Solutions</td>\n",
       "      <td>Calgary, AB</td>\n",
       "      <td>None</td>\n",
       "      <td>Director, Azure Data &amp; Analytics</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>118</td>\n",
       "      <td>AltaML Inc./Janalta Interactive Inc.</td>\n",
       "      <td>Calgary, AB</td>\n",
       "      <td>None</td>\n",
       "      <td>Machine Learning Team Lead</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>119</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>Montréal, QC</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Data Scientist - QuantumBlack</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>120</td>\n",
       "      <td>The Toronto Region Board of Trade</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>121</td>\n",
       "      <td>Manulife</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>122</td>\n",
       "      <td>OSL Retail Services Inc</td>\n",
       "      <td>Mississauga, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Vice President Business Analytics and Data</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>123</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>Waterloo, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>124</td>\n",
       "      <td>IQVIA</td>\n",
       "      <td>Kirkland, QC</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Analyst-Bilingual French &amp; English</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>125</td>\n",
       "      <td>Providence Health Care</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>126</td>\n",
       "      <td>Ada Inc.</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Machine Learning Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>127</td>\n",
       "      <td>Bond Brand Loyalty Inc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>128</td>\n",
       "      <td>Geotab</td>\n",
       "      <td>Oakville, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Applied Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>129</td>\n",
       "      <td>Restaurant Brands International</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist, People Analytics</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>130</td>\n",
       "      <td>Temetrix</td>\n",
       "      <td>Ottawa, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>131</td>\n",
       "      <td>Kabam</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>132</td>\n",
       "      <td>Marine Thinking Inc.</td>\n",
       "      <td>Halifax, NS</td>\n",
       "      <td>None</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>133</td>\n",
       "      <td>Zynga</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Science Intern - Summer 2021</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>134</td>\n",
       "      <td>ChilliConnect</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>None</td>\n",
       "      <td>Machine Learning Intern (ML-Agents), AI@Unity</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>135</td>\n",
       "      <td>Eastside Games</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>Game Data Analyst</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>136</td>\n",
       "      <td>Suncor Energy Services</td>\n",
       "      <td>Calgary, AB</td>\n",
       "      <td>None</td>\n",
       "      <td>Analytics Design and Delivery Leader</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>137</td>\n",
       "      <td>Xero</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Applied Scientist - Machine Learning Pr...</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>138</td>\n",
       "      <td>Ontario Energy Board</td>\n",
       "      <td>Toronto, ON</td>\n",
       "      <td>None</td>\n",
       "      <td>Summer Student - Performance Analytics &amp; Repor...</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>139</td>\n",
       "      <td>Enterprise Solutions Inc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>140</td>\n",
       "      <td>Relay Medical Corp.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Science / Machine Vision Intern</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>141</td>\n",
       "      <td>autoTRADER.ca</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>142</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Business Intelligence and Analytics Developer</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>143</td>\n",
       "      <td>Léger</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>144</td>\n",
       "      <td>FORM</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>73561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                     Company  \\\n",
       "0        0  Advanced Analytics and Research Lab (AAARL   \n",
       "1       15                               WeyMedia Inc.   \n",
       "2        4                                   TransLink   \n",
       "3        3                                    ProCogia   \n",
       "4       18                                    ProCogia   \n",
       "5        0                                  Nidish LLC   \n",
       "6        1                               CANN Forecast   \n",
       "7        1                      BC Pension Corporation   \n",
       "8        7                                     DocuPet   \n",
       "9       17                            Oliver Solutions   \n",
       "10       9                         Mastech InfoTrellis   \n",
       "11       5                       Fuze HR Solutions Inc   \n",
       "12      11                       Fuze HR Solutions Inc   \n",
       "13      12                       Fuze HR Solutions Inc   \n",
       "14      13                       Fuze HR Solutions Inc   \n",
       "15       0                     Innovation Credit Union   \n",
       "16      16                             Staffinity Inc.   \n",
       "17       6                             Staffinity Inc.   \n",
       "18       2                             Staffinity Inc.   \n",
       "19      14                             Staffinity Inc.   \n",
       "20       8      Canadian Security Intelligence Service   \n",
       "21      10         Advanced Analytics and Research Lab   \n",
       "22       0                         Relay Medical Corp.   \n",
       "23       1                               autoTRADER.ca   \n",
       "24       2                                   TC Energy   \n",
       "25       3                                  John Deere   \n",
       "26       4                             Targeted Talent   \n",
       "27       5                                       Léger   \n",
       "28       6                                        None   \n",
       "29       7                              General Motors   \n",
       "..     ...                                         ...   \n",
       "137    115                                BrainStation   \n",
       "138    116                                       Aviva   \n",
       "139    117                           Hitachi Solutions   \n",
       "140    118        AltaML Inc./Janalta Interactive Inc.   \n",
       "141    119                          McKinsey & Company   \n",
       "142    120           The Toronto Region Board of Trade   \n",
       "143    121                                    Manulife   \n",
       "144    122                     OSL Retail Services Inc   \n",
       "145    123                                      McAfee   \n",
       "146    124                                       IQVIA   \n",
       "147    125                      Providence Health Care   \n",
       "148    126                                    Ada Inc.   \n",
       "149    127                      Bond Brand Loyalty Inc   \n",
       "150    128                                      Geotab   \n",
       "151    129             Restaurant Brands International   \n",
       "152    130                                    Temetrix   \n",
       "153    131                                       Kabam   \n",
       "154    132                        Marine Thinking Inc.   \n",
       "155    133                                       Zynga   \n",
       "156    134                               ChilliConnect   \n",
       "157    135                              Eastside Games   \n",
       "158    136                      Suncor Energy Services   \n",
       "159    137                                        Xero   \n",
       "160    138                        Ontario Energy Board   \n",
       "161    139                    Enterprise Solutions Inc   \n",
       "162    140                         Relay Medical Corp.   \n",
       "163    141                               autoTRADER.ca   \n",
       "164    142                                        None   \n",
       "165    143                                       Léger   \n",
       "166    144                                        FORM   \n",
       "\n",
       "                                 Location  Salary  \\\n",
       "0                              Toronto ON   21000   \n",
       "1                                    None   30000   \n",
       "2    Metro Vancouver Regional District BC   34282   \n",
       "3                            Vancouver BC   35000   \n",
       "4                                    None   35000   \n",
       "5                                  Remote   46800   \n",
       "6                             Montréal QC   47840   \n",
       "7                             Victoria BC   53900   \n",
       "8                              Calgary AB   70000   \n",
       "9                              Toronto ON   85000   \n",
       "10                              Ottawa ON   88452   \n",
       "11                                   None   90000   \n",
       "12                                   None   90000   \n",
       "13                                   None   90000   \n",
       "14                                   None   90000   \n",
       "15                                 Canada   92629   \n",
       "16                                   None  100000   \n",
       "17                                   None  100000   \n",
       "18                                   None  100000   \n",
       "19                                   None  100000   \n",
       "20                              Ottawa ON  105705   \n",
       "21                             Toronto ON  112737   \n",
       "22                                   None    None   \n",
       "23                                   None    None   \n",
       "24                            Calgary, AB    None   \n",
       "25                                Ontario    None   \n",
       "26                        Quebec City, QC    None   \n",
       "27                                   None    None   \n",
       "28                                   None    None   \n",
       "29                                Ontario    None   \n",
       "..                                    ...     ...   \n",
       "137                         Vancouver, BC    None   \n",
       "138                           Markham, ON    None   \n",
       "139                           Calgary, AB    None   \n",
       "140                           Calgary, AB    None   \n",
       "141                          Montréal, QC    None   \n",
       "142                           Toronto, ON    None   \n",
       "143                           Toronto, ON    None   \n",
       "144                       Mississauga, ON    None   \n",
       "145                          Waterloo, ON    None   \n",
       "146                          Kirkland, QC    None   \n",
       "147                         Vancouver, BC    None   \n",
       "148                           Toronto, ON    None   \n",
       "149                                  None    None   \n",
       "150                          Oakville, ON    None   \n",
       "151                           Toronto, ON    None   \n",
       "152                            Ottawa, ON    None   \n",
       "153                         Vancouver, BC    None   \n",
       "154                           Halifax, NS    None   \n",
       "155                           Toronto, ON    None   \n",
       "156                         Vancouver, BC    None   \n",
       "157                                Remote    None   \n",
       "158                           Calgary, AB    None   \n",
       "159                           Toronto, ON    None   \n",
       "160                           Toronto, ON    None   \n",
       "161                                  None    None   \n",
       "162                                  None    None   \n",
       "163                                  None    None   \n",
       "164                                  None    None   \n",
       "165                                  None    None   \n",
       "166                                  None    None   \n",
       "\n",
       "                                                 Title  Salary  \n",
       "0                Analytics Client Lead and Development   21000  \n",
       "1                         Senior Business Data Analyst   30000  \n",
       "2               Data Scientist - Bus Priority Programs   34282  \n",
       "3                              Data Science Consultant   35000  \n",
       "4                              Data Science Consultant   35000  \n",
       "5                                       Data Scientist   46800  \n",
       "6    CANN FORECAST | Machine Learning/Statistical A...   47840  \n",
       "7                                       Data Scientist   53900  \n",
       "8                                         Data Analyst   70000  \n",
       "9                      Data Science and Analytics (DAS   85000  \n",
       "10                                      Data Scientist   88452  \n",
       "11                                      Data Scientist   90000  \n",
       "12                                      Data Scientist   90000  \n",
       "13                                      Data Scientist   90000  \n",
       "14                                      Data Scientist   90000  \n",
       "15                                      Data Scientist   92629  \n",
       "16            Data Scientist/Machine Learning Engineer  100000  \n",
       "17            Data Scientist/Machine Learning Engineer  100000  \n",
       "18            Data Scientist/Machine Learning Engineer  100000  \n",
       "19            Data Scientist/Machine Learning Engineer  100000  \n",
       "20                                      Data Scientist  105705  \n",
       "21                 Advanced Analytics and Research Lab  112737  \n",
       "22                Data Science / Machine Vision Intern   73561  \n",
       "23                                      Data Scientist   73561  \n",
       "24                            Integrity Data Scientist   73561  \n",
       "25                                       Data Wrangler   73561  \n",
       "26                                      Data Scientist   73561  \n",
       "27                                      Data Scientist   73561  \n",
       "28       Business Intelligence and Analytics Developer   73561  \n",
       "29            Data Scientist - CCA Co-Op (Spring 2021)   73561  \n",
       "..                                                 ...     ...  \n",
       "137                 Associate Educator, Data Scientist   73561  \n",
       "138                  Manager, Data Science Engineering   73561  \n",
       "139                   Director, Azure Data & Analytics   73561  \n",
       "140                         Machine Learning Team Lead   73561  \n",
       "141               Senior Data Scientist - QuantumBlack   73561  \n",
       "142                      Business Intelligence Analyst   73561  \n",
       "143                                Senior Data Analyst   73561  \n",
       "144         Vice President Business Analytics and Data   73561  \n",
       "145                                Senior Data Analyst   73561  \n",
       "146            Data Analyst-Bilingual French & English   73561  \n",
       "147                                     Data Scientist   73561  \n",
       "148                  Senior Machine Learning Scientist   73561  \n",
       "149                                   Sr. Data Analyst   73561  \n",
       "150                             Applied Data Scientist   73561  \n",
       "151                   Data Scientist, People Analytics   73561  \n",
       "152                              SENIOR DATA SCIENTIST   73561  \n",
       "153                                     Data Scientist   73561  \n",
       "154                           Principal Data Scientist   73561  \n",
       "155                  Data Science Intern - Summer 2021   73561  \n",
       "156      Machine Learning Intern (ML-Agents), AI@Unity   73561  \n",
       "157                                  Game Data Analyst   73561  \n",
       "158               Analytics Design and Delivery Leader   73561  \n",
       "159  Senior Applied Scientist - Machine Learning Pr...   73561  \n",
       "160  Summer Student - Performance Analytics & Repor...   73561  \n",
       "161                                     Data Analytics   73561  \n",
       "162               Data Science / Machine Vision Intern   73561  \n",
       "163                                     Data Scientist   73561  \n",
       "164      Business Intelligence and Analytics Developer   73561  \n",
       "165                                     Data Scientist   73561  \n",
       "166                                     Data Scientist   73561  \n",
       "\n",
       "[167 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5c = pd.concat([data_sal_all_1, data5ba], axis=1)\n",
    "data5c.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two Salary columns in our dataframe, so we rename the old one to Salary_1 and drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Title</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advanced Analytics and Research Lab (AAARL</td>\n",
       "      <td>Toronto ON</td>\n",
       "      <td>Analytics Client Lead and Development</td>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WeyMedia Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>Senior Business Data Analyst</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TransLink</td>\n",
       "      <td>Metro Vancouver Regional District BC</td>\n",
       "      <td>Data Scientist - Bus Priority Programs</td>\n",
       "      <td>34282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ProCogia</td>\n",
       "      <td>Vancouver BC</td>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ProCogia</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Company  \\\n",
       "0   Advanced Analytics and Research Lab (AAARL   \n",
       "15                               WeyMedia Inc.   \n",
       "4                                    TransLink   \n",
       "3                                     ProCogia   \n",
       "18                                    ProCogia   \n",
       "\n",
       "                                Location  \\\n",
       "0                             Toronto ON   \n",
       "15                                  None   \n",
       "4   Metro Vancouver Regional District BC   \n",
       "3                           Vancouver BC   \n",
       "18                                  None   \n",
       "\n",
       "                                     Title  Salary  \n",
       "0    Analytics Client Lead and Development   21000  \n",
       "15            Senior Business Data Analyst   30000  \n",
       "4   Data Scientist - Bus Priority Programs   34282  \n",
       "3                  Data Science Consultant   35000  \n",
       "18                 Data Science Consultant   35000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5c.columns = ['Company', 'Location', 'Salary_1', 'Title', 'Salary']\n",
    "data5d = data5c.drop(['Salary_1'], axis=1)\n",
    "data5d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15-February-2021'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Textual month, day and year\n",
    "d2 = today.strftime(\"%d-%B-%Y\")\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5d.to_csv('data/data-'+str(d2)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's procede with the cleanup of our dataset. Let's drop the cells that don't have any location as it won't be useful to us in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6a = data5d.replace('None',np.nan, regex=True)\n",
    "data6 = data6a[pd.notnull(data5d[\"Location\"])]\n",
    "data6 = data6.reset_index(drop=True)\n",
    "data7 = data6.groupby('Location').count()\n",
    "sort_data = data7.sort_values('Title',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, <b>sort_data</b> has a location <b>Canada</b>. We need to drop that row. Since we made our code flexible by asking the user to input his job title, this field might not show up in other job titles. Hence we need to write the code that will check if this field is there, and if it, drop it, else procede without doing anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_data_canada_1 = sort_data.reset_index()\n",
    "sort_data_canada_2 = sort_data_canada_1.iloc[:, 0]\n",
    "sort_data_canada_3 = sort_data_canada_2.isin(['Canada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sort_data_canada_3.any() == True:\n",
    "    sort_data_1 = sort_data.drop(['Canada'], axis=0)\n",
    "else:\n",
    "    sort_data_1 = sort_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_data_2 = sort_data_1.reset_index()\n",
    "sort_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split the location into <b>City</b> and <b>Provience</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = sort_data_2['Location'].str.split(',', expand=True)\n",
    "data1.columns = ['City', 'Provience']\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's merge this new data with the previous data and drop the column <b>Location</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([data1, sort_data_2], axis=1, sort=False)\n",
    "data3 = data2.drop(['Location'], axis=1)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which <b>Provience</b> has the maximum number of jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data3.groupby('Provience')['Title'].apply(lambda x: ', '.join(x.astype(str))).reset_index()\n",
    "data5 = data4['Title'].str.split(',', expand=True)\n",
    "data5.iloc[:, :] = data5.iloc[:, :].astype(float)\n",
    "data5['Total'] = data5.sum(axis=1).astype(int)\n",
    "data8 = data5.loc[:, 'Total']\n",
    "data9 = data4.loc[:, 'Provience']\n",
    "data10 = pd.concat([data9, data8], axis=1, sort=True)\n",
    "data10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the dataframe by which <b>City</b> has the maximum number of jobs and arrange it in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data11 = sort_data_1\n",
    "data11.sort_values(by='Title', ascending=True, inplace=True)\n",
    "data12 = data11.loc[:, 'Title']\n",
    "data13 = data12.tail(15)\n",
    "data13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure we don't have any duplicated in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data5d.drop_duplicates(keep=False,inplace=True)\n",
    "data5d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, many job titles have the same salary listed. For our last step, data visualization, we don’t need same salaries for different job titles, we just need one. So we group them by salary and then sort them in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5e = data5d.groupby('Salary')['Company'].apply(' '.join).reset_index()\n",
    "data5e.sort_values(by='Salary', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sal_all_1 = data5e.loc[:,'Salary']\n",
    "data_sal_all_2 = data_sal_all_1.tail(15)\n",
    "data_sal_all_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot which city has the maximum number of jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13.plot(kind='barh', figsize=(12, 12), color='steelblue')\n",
    "plt.xlabel('Number of jobs')\n",
    "plt.title(job_title_1+' jobs in Canada')\n",
    "\n",
    "for index, value in enumerate(data13): \n",
    "    label = format(int(value), ',')\n",
    "    \n",
    "    plt.annotate(label, xy=(value - 0.75, index - 0.10), color='white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plao the salary range as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sal_all_2.plot(kind='barh', figsize=(15, 15), color='grey')\n",
    "plt.xlabel('Salary')\n",
    "plt.title(job_title_1+' salary in Canada')\n",
    "\n",
    "for index, value in enumerate(data_sal_all_2): \n",
    "    label = format(int(value), ',') # format int with commas\n",
    "    \n",
    "    plt.annotate(label, xy=(value - 12000, index - 0.10), color='white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
